// api/chat.js
// Vercel Serverless Function - AI èŠå¤© API
// å¤„ç†ä¸ OC çš„å®æ—¶å¯¹è¯

async function handler(req, res) {
    // åªå…è®¸ POST è¯·æ±‚
    if (req.method !== 'POST') {
        return res.status(405).json({
            success: false,
            error: 'Method not allowed. Please use POST.'
        });
    }

    try {
        const {
            apiKey,
            apiUrl,
            apiModel,
            aiService = 'openai',
            systemPrompt,  // âœ… æ”¹ä¸ºæ¥æ”¶å‰ç«¯ç”Ÿæˆçš„å®Œæ•´ System Prompt
            message,
            chatHistory = [],
            ignoreHistory = false  // âœ… æ˜¯å¦å¿½ç•¥å†å²è®°å½•
        } = req.body;

        // å‚æ•°éªŒè¯
        if (!apiKey) {
            return res.status(400).json({
                success: false,
                error: 'APIå¯†é’¥ä¸èƒ½ä¸ºç©º'
            });
        }

        if (!apiUrl) {
            return res.status(400).json({
                success: false,
                error: 'API URLä¸èƒ½ä¸ºç©º'
            });
        }

        if (!systemPrompt) {
            return res.status(400).json({
                success: false,
                error: 'System Promptä¸èƒ½ä¸ºç©º'
            });
        }

        if (!message || message.trim() === '') {
            return res.status(400).json({
                success: false,
                error: 'æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º'
            });
        }

        // ğŸ” è°ƒè¯•ï¼šæ‰“å°æ¥æ”¶åˆ°çš„ System Promptï¼ˆå¯åœ¨Vercelæ—¥å¿—ä¸­æŸ¥çœ‹ï¼‰
        console.log('=== AIèŠå¤© - æ¥æ”¶å‰ç«¯ç”Ÿæˆçš„ System Prompt ===');
        console.log('System Prompt (å‰300å­—ç¬¦):', systemPrompt.substring(0, 300) + '...');
        console.log('ç”¨æˆ·æ¶ˆæ¯:', message);
        console.log('èŠå¤©å†å²æ¡æ•°:', chatHistory.length);
        console.log('å¿½ç•¥å†å²:', ignoreHistory);
        console.log('=== ç³»ç»Ÿæç¤ºè¯ç»“æŸ ===\n');

        // âœ… å¦‚æœè®¾ç½®äº†å¿½ç•¥å†å²ï¼Œåˆ™ä¸å‘é€å†å²è®°å½•ç»™AI
        let conversationHistory;
        if (ignoreHistory) {
            console.log('âœ… å¿½ç•¥å†å²æ¨¡å¼ï¼šä¸å‘é€å†å²è®°å½•ç»™AI');
            conversationHistory = buildConversationHistory([], message);
        } else {
            conversationHistory = buildConversationHistory(chatHistory, message);
        }

        // è°ƒç”¨ LLM API
        const llmResponse = await callChatLLMAPI(
            apiKey,
            apiUrl,
            apiModel,
            aiService,
            systemPrompt,  // âœ… ç›´æ¥ä½¿ç”¨å‰ç«¯ä¼ æ¥çš„å®Œæ•´ System Prompt
            conversationHistory
        );

        // æå–å›å¤å†…å®¹
        const reply = extractReply(llmResponse);

        // âœ… æš‚æ—¶è¿”å›ç©ºçš„å»ºè®®åŠ¨ä½œï¼ˆå‰ç«¯å¯ä»¥æ ¹æ®çŠ¶æ€ç”Ÿæˆï¼‰
        const suggestedActions = [];

        // è¿”å›æˆåŠŸå“åº”
        return res.status(200).json({
            success: true,
            data: {
                reply: reply,
                suggestedActions: suggestedActions
            }
        });

    } catch (error) {
        console.error('èŠå¤©APIé”™è¯¯:', error);

        // è¿”å›é”™è¯¯å“åº”
        return res.status(500).json({
            success: false,
            error: error.message || 'èŠå¤©å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•'
        });
    }
}

// ============================================
// è¾…åŠ©å‡½æ•°
// ============================================

/**
 * æ„å»ºå¯¹è¯å†å²
 * @param {array} chatHistory - èŠå¤©å†å²
 * @param {string} currentMessage - å½“å‰æ¶ˆæ¯
 * @returns {array} å¯¹è¯å†å²æ•°ç»„
 */
function buildConversationHistory(chatHistory, currentMessage) {
    const messages = [];
    const maxHistoryLength = 20; // æœ€å¤šä¿ç•™æœ€è¿‘20æ¡å†å²

    // é™åˆ¶å†å²é•¿åº¦
    const recentHistory = chatHistory.slice(-maxHistoryLength);

    // æ·»åŠ å†å²æ¶ˆæ¯
    recentHistory.forEach((msg, index) => {
        if (msg.role === 'user') {
            messages.push({
                role: 'user',
                content: msg.content
            });
        } else if (msg.role === 'assistant') {
            messages.push({
                role: 'assistant',
                content: msg.content
            });
        }
    });

    // æ·»åŠ å½“å‰æ¶ˆæ¯
    messages.push({
        role: 'user',
        content: currentMessage
    });

    return messages;
}

/**
 * è°ƒç”¨ LLM API
 * @param {string} apiKey - APIå¯†é’¥
 * @param {string} apiUrl - APIåœ°å€
 * @param {string} model - æ¨¡å‹åç§°
 * @param {string} service - AIæœåŠ¡ç±»å‹
 * @param {string} systemPrompt - ç³»ç»Ÿæç¤ºè¯
 * @param {array} messages - å¯¹è¯å†å²
 * @returns {object} APIå“åº”
 */
async function callChatLLMAPI(apiKey, apiUrl, model, service, systemPrompt, messages) {
    const requestBody = {
        model: model,
        messages: [
            {
                role: 'system',
                content: systemPrompt
            },
            ...messages
        ],
        temperature: 0.8,
        max_tokens: 150,
        stream: false
    };

    // ğŸ” è°ƒè¯•æ—¥å¿—
    console.log('ğŸ“¤ è°ƒç”¨ LLM API:');
    console.log('  URL:', apiUrl);
    console.log('  Model:', model);
    console.log('  Service:', service);

    const response = await fetch(apiUrl, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`
        },
        body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
        const errorText = await response.text();
        console.error('âŒ LLM API é”™è¯¯å“åº”:');
        console.error('  Status:', response.status, response.statusText);
        console.error('  Response:', errorText);

        let errorData;
        try {
            errorData = JSON.parse(errorText);
        } catch (e) {
            errorData = { raw: errorText };
        }

        throw new Error(errorData.error?.message || errorData.message || `APIè¯·æ±‚å¤±è´¥: ${response.status} - ${errorText.substring(0, 200)}`);
    }

    return await response.json();
}

/**
 * ä»APIå“åº”ä¸­æå–å›å¤å†…å®¹
 * @param {object} llmResponse - LLM APIå“åº”
 * @returns {string} å›å¤å†…å®¹
 */
function extractReply(llmResponse) {
    if (llmResponse.choices && llmResponse.choices.length > 0) {
        return llmResponse.choices[0].message.content.trim();
    }
    return 'æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›å¤ã€‚';
}

/**
 * æ ¼å¼åŒ–æ—¶é•¿
 * @param {number} seconds - ç§’æ•°
 * @returns {string} æ ¼å¼åŒ–åçš„æ—¶é•¿
 */
function formatDuration(seconds) {
    const hours = Math.floor(seconds / 3600);
    const minutes = Math.floor((seconds % 3600) / 60);

    if (hours > 0) {
        return `${hours}å°æ—¶${minutes}åˆ†é’Ÿ`;
    }
    return `${minutes}åˆ†é’Ÿ`;
}

// å¯¼å‡ºå‡½æ•° - åŒæ—¶æ”¯æŒ CommonJS å’Œ ES Module
module.exports = {
    default: handler,  // âœ… æ·»åŠ  default å¯¼å‡º
    handler,
    buildConversationHistory,
    formatDuration
};

// Vercel éƒ¨ç½²æ—¶ä½¿ç”¨ (ç¡®ä¿ default å­˜åœ¨)
if (typeof exports !== 'undefined') {
    exports.default = handler;
}
